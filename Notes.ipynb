{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a2d0e4",
   "metadata": {},
   "source": [
    "## **Intro**\n",
    "\n",
    "> Latest version of `Pytorch` is `2.10.0` (as of 2026)\n",
    "\n",
    "`Pytorch` is a popular open-source Deep Learning Library developed by `Facebook's AI Research lab (FAIR)`. In 2002, `Torch` was developed with `Lua` especially for performing `Tesnsor` based computations. In 2016, `Pytorch` was developed as a Python version of `Torch` and it has been widely used in the field of `Deep Learning` since then.\n",
    "\n",
    "`Pytorch` provides a flexible and dynamic computational graph. \n",
    "\n",
    "**Computational Graph** is a way to represent mathematical computations as a graph, where nodes represent operations and edges represent the flow of data. In `Pytorch`, the computational graph is dynamic, which means that it can be modified on-the-fly during runtime. This allows for more flexibility in building and training neural networks, as you can easily change the architecture or the operations being performed without having to redefine the entire graph.\n",
    "\n",
    "**ONNX(Open Neural Network Exchange)** is an open format for representing machine learning models. It allows models to be transferred between different frameworks, such as `Pytorch`, `TensorFlow`, and `Caffe2`. This means that you can train a model in one framework and then export it to another framework for inference or deployment.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### **Core Features of `Pytorch`**\n",
    "\n",
    "**Tensor Computations**: `Pytorch` provides a powerful and efficient way to perform tensor computations. Tensors are multi-dimensional arrays that can be used to represent data in various forms, such as images, text, and audio. `Pytorch` provides a wide range of operations for manipulating tensors, including mathematical operations, indexing, slicing, and broadcasting.\n",
    "\n",
    "**Dynamic Computational Graph**: As mentioned earlier, `Pytorch` uses a dynamic computational graph, which allows for more flexibility in building and training neural networks. This means that you can easily change the architecture or the operations being performed without having to redefine the entire graph.\n",
    "\n",
    "**GPU Acceleration**: `Pytorch` supports GPU acceleration, which allows for faster training and inference of neural networks. This is particularly important when working with large datasets or complex models.\n",
    "\n",
    "**Autograd**: `Pytorch` provides an automatic differentiation system called `Autograd`, which allows for easy computation of gradients. This is essential for training neural networks using backpropagation.\n",
    "\n",
    "**Distributed Training**: `Pytorch` supports distributed training, which allows for training large models across multiple GPUs or even multiple machines. This can significantly reduce the time required to train complex models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
