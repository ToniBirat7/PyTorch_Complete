{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b778789a",
   "metadata": {},
   "source": [
    "> Currently following resources\n",
    "\n",
    "[CampusX_PyTorch_Complete](https://www.youtube.com/watch?v=mDsFsnw3SK4&list=PLKnIA16_Rmvboy8bmDCjwNHgTaYH2puK7&index=3)\n",
    "\n",
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2d0e4",
   "metadata": {},
   "source": [
    "## **Intro**\n",
    "\n",
    "> Latest version of `Pytorch` is `2.10.0` (as of 2026)\n",
    "\n",
    "`Pytorch` is a popular open-source Deep Learning Library developed by `Facebook's AI Research lab (FAIR)`. In 2002, `Torch` was developed with `Lua` especially for performing `Tesnsor` based computations. In 2016, `Pytorch` was developed as a Python version of `Torch` and it has been widely used in the field of `Deep Learning` since then.\n",
    "\n",
    "`Pytorch` provides a flexible and dynamic computational graph. \n",
    "\n",
    "**Computational Graph** is a way to represent mathematical computations as a graph, where nodes represent operations and edges represent the flow of data. In `Pytorch`, the computational graph is dynamic, which means that it can be modified on-the-fly during runtime. This allows for more flexibility in building and training neural networks, as you can easily change the architecture or the operations being performed without having to redefine the entire graph.\n",
    "\n",
    "**ONNX(Open Neural Network Exchange)** is an open format for representing machine learning models. It allows models to be transferred between different frameworks, such as `Pytorch`, `TensorFlow`, and `Caffe2`. This means that you can train a model in one framework and then export it to another framework for inference or deployment.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### **Core Features of `Pytorch`**\n",
    "\n",
    "**Tensor Computations**: `Pytorch` provides a powerful and efficient way to perform tensor computations. Tensors are multi-dimensional arrays that can be used to represent data in various forms, such as images, text, and audio. `Pytorch` provides a wide range of operations for manipulating tensors, including mathematical operations, indexing, slicing, and broadcasting.\n",
    "\n",
    "**Dynamic Computational Graph**: As mentioned earlier, `Pytorch` uses a dynamic computational graph, which allows for more flexibility in building and training neural networks. This means that you can easily change the architecture or the operations being performed without having to redefine the entire graph.\n",
    "\n",
    "**GPU Acceleration**: `Pytorch` supports GPU acceleration, which allows for faster training and inference of neural networks. This is particularly important when working with large datasets or complex models.\n",
    "\n",
    "**Autograd**: `Pytorch` provides an automatic differentiation system called `Autograd`, which allows for easy computation of gradients. This is essential for training neural networks using backpropagation.\n",
    "\n",
    "**Distributed Training**: `Pytorch` supports distributed training, which allows for training large models across multiple GPUs or even multiple machines. This can significantly reduce the time required to train complex models.\n",
    "\n",
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81373000",
   "metadata": {},
   "source": [
    "## **Tensors**\n",
    "\n",
    "Just like we've other data structures like `arrays`, `lists`, `dataframes`, etc. Each data structure has its own use case. For example, `arrays` are used for numerical computations, `lists` are used for storing collections of items, and `dataframes` are used for tabular data. \n",
    "\n",
    "In similar fashion, `tensors` is a specialized multi-dimensional array designed for mathematical and computational tasks.\n",
    "\n",
    "> Note: Here we are talking about `Tensors` in the context of `Computation`. Actually, `Tensor` is a general term used in mathematics and physics to describe a geometric object that generalizes scalars, vectors, and matrices to higher dimensions and remains consistent under coordinate transformations. \n",
    "\n",
    "In `PyTorch`, a `Tensor` is just a multi-dimensional array that can be used to represent data in various forms, such as images, text, and audio.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### **Understanding Tensors with Real World Examples**\n",
    "\n",
    "**Zero Dimensional Tensor (Scalar)**: A zero-dimensional tensor does not have a direction or orientation. It is simply a single value, like a number. For example, the `temperature` at a specific location can be represented as a zero-dimensional tensor.\n",
    "\n",
    "**One Dimensional Tensor (Vector)**: A one-dimensional tensor has a direction and can be represented as a list of values. For example, the `daily temperatures` for a week can be represented as a one-dimensional tensor i.e. `[30, 32, 28, 31, 29, 27, 33]`.\n",
    "\n",
    "**Two Dimensional Tensor (Matrix)**: A two-dimensional tensor has two directions and can be represented as a table of values. For example, the `pixel values` of a grayscale image can be represented as a two-dimensional tensor, where each value represents the intensity of the pixel.\n",
    "\n",
    "**Three Dimensional Tensor**: A three-dimensional tensor has three directions and can be represented as a cube of values. For example, the `RGB pixel values` of a color image can be represented as a three-dimensional tensor, where each value represents the intensity of the red, green, and blue channels.\n",
    "\n",
    "<img src=\"./Notes_Images/3d_tensor.png\" alt=\"3D Tensor\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
